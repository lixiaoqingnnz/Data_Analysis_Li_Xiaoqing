<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>executive_summary</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="pdf.css" />
</head>
<body>
<h1 id="executive-summary">Executive Summary</h1>
<h2 id="project-deliverables">1. Project Deliverables</h2>
<p>This project successfully produced a fully reproducible Python
codebase that performs <strong>end-to-end automated report
generation</strong>.</p>
<ul>
<li><strong>Input:</strong> Structured dataset (Excel / CSV)<br />
</li>
<li><strong>Output:</strong> Complete business report in:
<code>.md</code> (Markdown) or <code>.html</code> (HTML) or
<code>.pdf</code> (PDF)</li>
</ul>
<h2 id="solution-architecture-and-design-choices">2. Solution
Architecture and Design Choices</h2>
<h3 id="workflow-pipeline">2.1 Workflow Pipeline</h3>
<figure>
<img src="pipeline_diagram.png" class="img-full"
alt="Workflow Pipeline" />
<figcaption aria-hidden="true">Workflow Pipeline</figcaption>
</figure>
<p>The workflow integrates data preprocessing, metric computation,
LLM-guided analysis, visualization generation, and automated report
assembly into a unified, reproducible pipeline. Its modular three-stage
design—clean data foundation, LLM-orchestrated analytical reasoning, and
structured multi-format report generation—enables a fully automated and
scalable transformation of raw structured data into actionable
insights.</p>
<h4 id="step-1-data-preprocessing">Step 1 — Data Preprocessing</h4>
<p>Perform data loading, column name normalization, type conversion,
missing value imputation, duplicate removal and produce a clean,
analysis-ready dataset.</p>
<p><strong>Data Context Assumption</strong>: Given the presence of the
Mileage_KM column in the raw dataset, this analysis proceeds with the
assumption that the input data represents transactions related to used
cars. This context guides the relevance of specific metrics and
visualizations.</p>
<h4 id="step-2-llm-orchestration-layer">Step 2 — LLM Orchestration
Layer</h4>
<p>    -<strong>Data Analysis</strong>: Precompute complex metrics and
aggregations to support chart and table generation.</p>
<p>    -<strong>Chart/Table Generation</strong>: Generate reproducible
visual assets using <strong>matplotlib</strong> or
<strong>seaborn</strong>, including trend plots, ranking charts, and
summary tables.</p>
<p>    -<strong>Analysis Summary for LLM Prompting</strong>: Combine
preprocessed data, computed metrics, and visual artifacts to construct a
structured prompt that guides the LLM in a
<strong>Chain-of-Thought</strong> fashion.</p>
<p>    -<strong>LLM-Driven Narrative Generation</strong>: Use the
<strong>OpenRouter API</strong> to call the selected LLM and generate
descriptive narrative insights for each analysis topic based on analysis
summary and specific instructions.</p>
<h4 id="step-3-final-report-generation">Step 3 — Final Report
Generation</h4>
<p>Each analysis insight is encapsulated as a structured JSON object,
enabling modular assembly and reproducible report synthesis. These
insights are consolidated into a unified Markdown document, followed by
a two-stage conversion pipeline (Markdown → HTML via Pandoc, then HTML →
PDF via WeasyPrint) that ensures consistent styling, layout control, and
portable final outputs.</p>
<h3 id="coverage-of-required-llm-driven-analytical-tasks">2.2 Coverage
of Required LLM-Driven Analytical Tasks</h3>
<p>The LLM orchestration layer is designed to fully satisfy all required
analytic capabilities in the case study specification, including trend
identification over time and region, top-performing and underperforming
segments, key drives of sales and additional creative insights (2025
sales forecast using ML).</p>
<h2 id="model-selection-and-evaluation">3. Model Selection and
Evaluation</h2>
<h3 id="llm-model-selection">3.1 LLM Model Selection</h3>
<p>The project uses the <strong>“openai/gpt-oss-20b:free”</strong> model
via <strong>OpenRouter API</strong> as this model currently offers one
of the strongest performance levels among the freely accessible large
models on OpenRouter.</p>
<h3
id="machine-learning-forecast-model-selection-creative-insight-extension">3.2
Machine Learning Forecast Model Selection (Creative Insight
Extension)</h3>
<figure>
<img src="model_performance_2024_with_lag.png" class="img-mid"
alt="Machine Learning Forecast Model Performance" />
<figcaption aria-hidden="true">Machine Learning Forecast Model
Performance</figcaption>
</figure>
<p>Beyond the core requirements of LLM-driven analysis, this project
introduces a machine-learning forecasting module as a <strong>creative
analytical extension</strong>. Four ensemble models—XGBoost, LightGBM,
Random Forest, and CatBoost—were evaluated using lag-enhanced historical
data (2020–2024) with multiple evaluation metrics. CatBoost achieved the
highest accuracy on 2024 validation and was adopted for forecasting. The
final model provides 2025 predicted total sales and sales breakdowns by
model, region, fuel type, transmission, and color, supporting
data-driven planning for the coming year.</p>
<h3 id="evaluation-framework-and-multi-model-validation">3.3 Evaluation
Framework and Multi-Model Validation</h3>
<p>The project includes an <strong>automated evaluation
pipeline</strong> that extracts all numeric values from the
LLM-generated narratives and cross-checks them against the structured
analysis summary. This produces a quantifiable measure of narrative–data
alignment, yielding an overall numeric coverage rate of
<strong>75.17%</strong>. In addition to numeric evaluation,
<strong>multi-LLM qualitative assessments</strong> (using ChatGPT and
Gemini) were performed to review the final report’s completeness,
correctness, readability, and coherence.</p>
<!-- ## 4. Reproducibility and Code Quality

The codebase adopts a modular, deterministic, and fully reproducible design that cleanly separates orchestration from business logic, enforces consistent preprocessing and visualization outputs, and provides structured logging, error-handling, and unified styling across generated figures and Markdown, HTML, and PDF reports. -->
<h2 id="conclusion-and-future-outlook">4. Conclusion and Future
Outlook</h2>
<p>Future enhancements aimed at richer insight generation through
multimodal embeddings, stronger reasoning control via expanded
prompt-engineering, scheduled automation through CI/CD pipelines,
broader export options such as PowerPoint and dashboards, and deployment
as a lightweight microservice or serverless function for enterprise
integration.</p>
</body>
</html>
