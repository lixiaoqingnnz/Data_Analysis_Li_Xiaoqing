{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb60e81d",
   "metadata": {},
   "source": [
    "# Predicte 2025 sales: test on different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0abca04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated shape (before lag): (10306, 10)\n",
      "   year     model  region fuel_type transmission   color  engine_size_l  \\\n",
      "0  2020  3 Series  Africa    Diesel    Automatic   Black           2.90   \n",
      "1  2020  3 Series  Africa    Diesel    Automatic    Blue           3.00   \n",
      "2  2020  3 Series  Africa    Diesel    Automatic     Red           3.55   \n",
      "3  2020  3 Series  Africa    Diesel    Automatic  Silver           3.30   \n",
      "4  2020  3 Series  Africa    Diesel       Manual   Black           4.60   \n",
      "\n",
      "   mileage_km  price_usd  sales_volume  \n",
      "0     54293.0   100920.0          8279  \n",
      "1     22846.0    79435.5          6282  \n",
      "2     85078.5   106306.0         14847  \n",
      "3    182077.0    59951.0          2355  \n",
      "4    107799.0    75078.0          3975   \n",
      "\n",
      "Shape after adding lag features (before dropna): (10306, 18) \n",
      "\n",
      "Shape train (with lag): (2343, 17), Shape valid (with lag): (1808, 17)\n",
      "\n",
      "Model: XGBoost\n",
      "  MAE      : 789.90 (9.41%)\n",
      "  RMSE     : 1181.66 (14.08%)\n",
      "  MedianAE : 575.95 (6.86%)\n",
      "  MAPE     : 29.28%\n",
      "  R2       : 0.9559\n",
      "\n",
      "Model: LightGBM\n",
      "  MAE      : 635.31 (7.57%)\n",
      "  RMSE     : 1008.45 (12.01%)\n",
      "  MedianAE : 426.60 (5.08%)\n",
      "  MAPE     : 23.12%\n",
      "  R2       : 0.9679\n",
      "\n",
      "Model: RandomForest\n",
      "  MAE      : 920.21 (10.96%)\n",
      "  RMSE     : 1411.96 (16.82%)\n",
      "  MedianAE : 598.33 (7.13%)\n",
      "  MAPE     : 35.34%\n",
      "  R2       : 0.9370\n",
      "\n",
      "Model: CatBoost\n",
      "  MAE      : 374.77 (4.46%)\n",
      "  RMSE     : 706.72 (8.42%)\n",
      "  MedianAE : 225.13 (2.68%)\n",
      "  MAPE     : 12.76%\n",
      "  R2       : 0.9842\n",
      "\n",
      "\n",
      "=== Model comparison on 2024 validation (with lag, row-level) ===\n",
      "                 MAE         RMSE    MedianAE       MAPE        R2    MAE_pct  \\\n",
      "model                                                                           \n",
      "xgb       789.897461  1181.660034  575.946777  29.278055  0.955910   9.409003   \n",
      "lgbm      635.309728  1008.448650  426.595479  23.123558  0.967888   7.567604   \n",
      "rf        920.211801  1411.957242  598.328333  35.340780  0.937050  10.961265   \n",
      "catboost  374.766998   706.723730  225.126607  12.755740  0.984229   4.464103   \n",
      "\n",
      "           RMSE_pct  MedianAE_pct  \n",
      "model                              \n",
      "xgb       14.075552      6.860492  \n",
      "lgbm      12.012314      5.081467  \n",
      "rf        16.818778      7.127094  \n",
      "catboost   8.418264      2.681635   \n",
      "\n",
      "Saved bar chart to: model_performance_2024_with_lag.png\n",
      "\n",
      "\n",
      "=== CatBoost predicted total sales volume in 2025: 19529866.56 ===\n",
      "\n",
      "CatBoost - 2025 predicted sales by model:\n",
      "      model  pred_sales_volume_2025_catboost\n",
      "8        X6                     1.960037e+06\n",
      "2  7 Series                     1.889560e+06\n",
      "5        X1                     1.861147e+06\n",
      "4        M5                     1.829955e+06\n",
      "6        X3                     1.765595e+06 \n",
      "\n",
      "CatBoost - 2025 predicted sales by region:\n",
      "          region  pred_sales_volume_2025_catboost\n",
      "2         Europe                     3.418326e+06\n",
      "3    Middle East                     3.342179e+06\n",
      "1           Asia                     3.246769e+06\n",
      "4  North America                     3.216616e+06\n",
      "0         Africa                     3.172208e+06\n",
      "5  South America                     3.133768e+06 \n",
      "\n",
      "CatBoost - 2025 predicted sales by fuel_type:\n",
      "  fuel_type  pred_sales_volume_2025_catboost\n",
      "2    Hybrid                     5.003313e+06\n",
      "0    Diesel                     4.888898e+06\n",
      "1  Electric                     4.832577e+06\n",
      "3    Petrol                     4.805079e+06 \n",
      "\n",
      "CatBoost - 2025 predicted sales by transmission:\n",
      "  transmission  pred_sales_volume_2025_catboost\n",
      "1       Manual                     9.911152e+06\n",
      "0    Automatic                     9.618715e+06 \n",
      "\n",
      "CatBoost - 2025 predicted sales by color:\n",
      "    color  pred_sales_volume_2025_catboost\n",
      "3     Red                     3.379653e+06\n",
      "0   Black                     3.343638e+06\n",
      "1    Blue                     3.311630e+06\n",
      "5   White                     3.306206e+06\n",
      "4  Silver                     3.204625e+06\n",
      "2    Grey                     2.984115e+06 \n",
      "\n",
      "CatBoost (row-level) predicted 2025 total sales: 19529866.56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error,\n",
    "    r2_score,\n",
    "    median_absolute_error,\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# =========================================================\n",
    "# 0. Global configuration\n",
    "# =========================================================\n",
    "FILE_PATH = \"../data/processed/bmw_sales_2020_2024_clean.csv\"\n",
    "\n",
    "CAT_FEATURES = [\"model\", \"region\", \"fuel_type\", \"transmission\", \"color\"]\n",
    "NUM_FEATURES = [\"year\", \"engine_size_l\", \"mileage_km\", \"price_usd\"]\n",
    "FEATURE_COLS = CAT_FEATURES + NUM_FEATURES\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. Aggregate raw data (by year + category combination)\n",
    "# =========================================================\n",
    "def load_and_aggregate(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the raw data and aggregate by the combination of:\n",
    "        year + model + region + fuel_type + transmission + color.\n",
    "\n",
    "    Aggregation rules:\n",
    "        - engine_size_l, mileage_km, price_usd: mean value\n",
    "        - sales_volume: sum\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    group_cols = [\"year\", \"model\", \"region\", \"fuel_type\", \"transmission\", \"color\"]\n",
    "\n",
    "    agg_df = (\n",
    "        df.groupby(group_cols, as_index=False)\n",
    "        .agg(\n",
    "            {\n",
    "                \"engine_size_l\": \"mean\",\n",
    "                \"mileage_km\": \"mean\",\n",
    "                \"price_usd\": \"mean\",\n",
    "                \"sales_volume\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. Generic metric computation\n",
    "# =========================================================\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Compute regression metrics between ground truth and predictions.\n",
    "\n",
    "    Metrics:\n",
    "        - MAE\n",
    "        - RMSE\n",
    "        - MedianAE\n",
    "        - MAPE\n",
    "        - R2\n",
    "\n",
    "    Additionally, compute percentage metrics relative to the mean of y_true:\n",
    "        - MAE_pct\n",
    "        - RMSE_pct\n",
    "        - MedianAE_pct\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    med_ae = median_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Avoid division by zero when computing MAPE\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = (np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])).mean() * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "\n",
    "    # R2 is not meaningful for a single data point\n",
    "    if len(y_true) > 1:\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "    else:\n",
    "        r2 = np.nan\n",
    "\n",
    "    mean_y = y_true.mean()\n",
    "    mae_pct = mae / mean_y * 100 if mean_y != 0 else np.nan\n",
    "    rmse_pct = rmse / mean_y * 100 if mean_y != 0 else np.nan\n",
    "    med_ae_pct = med_ae / mean_y * 100 if mean_y != 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MedianAE\": med_ae,\n",
    "        \"MAPE\": mape,\n",
    "        \"R2\": r2,\n",
    "        \"MAE_pct\": mae_pct,\n",
    "        \"RMSE_pct\": rmse_pct,\n",
    "        \"MedianAE_pct\": med_ae_pct,\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. Lag feature construction (for ML models)\n",
    "# =========================================================\n",
    "def add_lag_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add lag-based features for each combination of:\n",
    "        model + region + fuel_type + transmission + color.\n",
    "\n",
    "    Newly created features:\n",
    "        - sales_last1, sales_last2\n",
    "        - sales_avg3\n",
    "        - sales_growth\n",
    "        - price_last1, price_trend\n",
    "        - mileage_last1, mileage_trend\n",
    "\n",
    "    The global NUM_FEATURES and FEATURE_COLS variables are updated accordingly.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\n",
    "        [\"model\", \"region\", \"fuel_type\", \"transmission\", \"color\", \"year\"]\n",
    "    ).copy()\n",
    "\n",
    "    group_cols = [\"model\", \"region\", \"fuel_type\", \"transmission\", \"color\"]\n",
    "\n",
    "    df[\"sales_last1\"] = df.groupby(group_cols)[\"sales_volume\"].shift(1)\n",
    "    df[\"sales_last2\"] = df.groupby(group_cols)[\"sales_volume\"].shift(2)\n",
    "\n",
    "    df[\"sales_avg3\"] = df.groupby(group_cols)[\"sales_volume\"].transform(\n",
    "        lambda x: x.rolling(3).mean()\n",
    "    )\n",
    "\n",
    "    df[\"sales_growth\"] = (df[\"sales_last1\"] - df[\"sales_last2\"]) / df[\"sales_last2\"]\n",
    "\n",
    "    df[\"price_last1\"] = df.groupby(group_cols)[\"price_usd\"].shift(1)\n",
    "    df[\"price_trend\"] = (df[\"price_usd\"] - df[\"price_last1\"]) / df[\"price_last1\"]\n",
    "\n",
    "    df[\"mileage_last1\"] = df.groupby(group_cols)[\"mileage_km\"].shift(1)\n",
    "    df[\"mileage_trend\"] = (df[\"mileage_km\"] - df[\"mileage_last1\"]) / df[\"mileage_last1\"]\n",
    "\n",
    "    # Update the global numeric feature list with lag-based features\n",
    "    lag_num_features = [\n",
    "        \"sales_last1\",\n",
    "        \"sales_last2\",\n",
    "        \"sales_avg3\",\n",
    "        \"sales_growth\",\n",
    "        \"price_last1\",\n",
    "        \"price_trend\",\n",
    "        \"mileage_last1\",\n",
    "        \"mileage_trend\",\n",
    "    ]\n",
    "\n",
    "    global NUM_FEATURES, FEATURE_COLS\n",
    "    NUM_FEATURES = [\"year\", \"engine_size_l\", \"mileage_km\", \"price_usd\"] + lag_num_features\n",
    "    FEATURE_COLS = CAT_FEATURES + NUM_FEATURES\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4. Model builders (pipelines and CatBoost model)\n",
    "# =========================================================\n",
    "def build_xgb_pipeline():\n",
    "    \"\"\"\n",
    "    Build an XGBoost regression pipeline with preprocessing.\n",
    "\n",
    "    The pipeline includes:\n",
    "        - One-hot encoding for categorical features\n",
    "        - Passthrough for numeric features\n",
    "        - XGBRegressor as the final estimator\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_FEATURES),\n",
    "            (\"num\", \"passthrough\", NUM_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    return Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", xgb)])\n",
    "\n",
    "\n",
    "def build_lgbm_pipeline():\n",
    "    \"\"\"\n",
    "    Build a LightGBM regression pipeline with preprocessing.\n",
    "\n",
    "    The pipeline includes:\n",
    "        - One-hot encoding for categorical features\n",
    "        - Passthrough for numeric features\n",
    "        - LGBMRegressor as the final estimator\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_FEATURES),\n",
    "            (\"num\", \"passthrough\", NUM_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lgbm = LGBMRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=-1,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        objective=\"regression\",\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    return Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", lgbm)])\n",
    "\n",
    "\n",
    "def build_rf_pipeline():\n",
    "    \"\"\"\n",
    "    Build a RandomForest regression pipeline with preprocessing.\n",
    "\n",
    "    The pipeline includes:\n",
    "        - One-hot encoding for categorical features\n",
    "        - Passthrough for numeric features\n",
    "        - RandomForestRegressor as the final estimator\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_FEATURES),\n",
    "            (\"num\", \"passthrough\", NUM_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    return Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", rf)])\n",
    "\n",
    "\n",
    "def build_catboost_model():\n",
    "    \"\"\"\n",
    "    Build a CatBoostRegressor model.\n",
    "\n",
    "    CatBoost consumes the raw DataFrame directly, with categorical\n",
    "    feature indices specified via cat_features.\n",
    "    \"\"\"\n",
    "    return CatBoostRegressor(\n",
    "        depth=8,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=800,\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 5. Training and validation (2020–2023 train, 2024 validate)\n",
    "# =========================================================\n",
    "def train_and_validate_models(df_lagged: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Train XGBoost, LightGBM, RandomForest, and CatBoost on data with lag features\n",
    "    and evaluate them on the 2024 validation set.\n",
    "\n",
    "    The training/validation split:\n",
    "        - Training: years < 2024\n",
    "        - Validation: year == 2024\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_lagged : pd.DataFrame\n",
    "        Input DataFrame containing lag-augmented features and sales_volume.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics_all : dict\n",
    "        Dictionary mapping model names to their evaluation metrics on 2024.\n",
    "    cat_model : CatBoostRegressor\n",
    "        Trained CatBoost model (for potential reuse).\n",
    "    \"\"\"\n",
    "    # Drop rows with missing lag features or target values\n",
    "    df_clean = df_lagged.dropna(subset=FEATURE_COLS + [\"sales_volume\"]).copy()\n",
    "\n",
    "    # Split by year\n",
    "    train_df = df_clean[df_clean[\"year\"] < 2024]\n",
    "    valid_df = df_clean[df_clean[\"year\"] == 2024]\n",
    "\n",
    "    X_train = train_df[FEATURE_COLS]\n",
    "    y_train = train_df[\"sales_volume\"].values\n",
    "\n",
    "    X_valid = valid_df[FEATURE_COLS]\n",
    "    y_valid = valid_df[\"sales_volume\"].values\n",
    "\n",
    "    print(\n",
    "        f\"Shape train (with lag): {X_train.shape}, \"\n",
    "        f\"Shape valid (with lag): {X_valid.shape}\\n\"\n",
    "    )\n",
    "\n",
    "    metrics_all = {}\n",
    "\n",
    "    # ---------- XGBoost ----------\n",
    "    xgb_model = build_xgb_pipeline()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb_model.predict(X_valid)\n",
    "    metrics_xgb = compute_metrics(y_valid, y_pred_xgb)\n",
    "    metrics_all[\"xgb\"] = metrics_xgb\n",
    "\n",
    "    print(\"Model: XGBoost\")\n",
    "    print(\n",
    "        f\"  MAE      : {metrics_xgb['MAE']:.2f} ({metrics_xgb['MAE_pct']:.2f}%)\\n\"\n",
    "        f\"  RMSE     : {metrics_xgb['RMSE']:.2f} ({metrics_xgb['RMSE_pct']:.2f}%)\\n\"\n",
    "        f\"  MedianAE : {metrics_xgb['MedianAE']:.2f} ({metrics_xgb['MedianAE_pct']:.2f}%)\\n\"\n",
    "        f\"  MAPE     : {metrics_xgb['MAPE']:.2f}%\\n\"\n",
    "        f\"  R2       : {metrics_xgb['R2']:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    # ---------- LightGBM ----------\n",
    "    lgbm_model = build_lgbm_pipeline()\n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "    y_pred_lgbm = lgbm_model.predict(X_valid)\n",
    "    metrics_lgbm = compute_metrics(y_valid, y_pred_lgbm)\n",
    "    metrics_all[\"lgbm\"] = metrics_lgbm\n",
    "\n",
    "    print(\"Model: LightGBM\")\n",
    "    print(\n",
    "        f\"  MAE      : {metrics_lgbm['MAE']:.2f} ({metrics_lgbm['MAE_pct']:.2f}%)\\n\"\n",
    "        f\"  RMSE     : {metrics_lgbm['RMSE']:.2f} ({metrics_lgbm['RMSE_pct']:.2f}%)\\n\"\n",
    "        f\"  MedianAE : {metrics_lgbm['MedianAE']:.2f} ({metrics_lgbm['MedianAE_pct']:.2f}%)\\n\"\n",
    "        f\"  MAPE     : {metrics_lgbm['MAPE']:.2f}%\\n\"\n",
    "        f\"  R2       : {metrics_lgbm['R2']:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    # ---------- RandomForest ----------\n",
    "    rf_model = build_rf_pipeline()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_valid)\n",
    "    metrics_rf = compute_metrics(y_valid, y_pred_rf)\n",
    "    metrics_all[\"rf\"] = metrics_rf\n",
    "\n",
    "    print(\"Model: RandomForest\")\n",
    "    print(\n",
    "        f\"  MAE      : {metrics_rf['MAE']:.2f} ({metrics_rf['MAE_pct']:.2f}%)\\n\"\n",
    "        f\"  RMSE     : {metrics_rf['RMSE']:.2f} ({metrics_rf['RMSE_pct']:.2f}%)\\n\"\n",
    "        f\"  MedianAE : {metrics_rf['MedianAE']:.2f} ({metrics_rf['MedianAE_pct']:.2f}%)\\n\"\n",
    "        f\"  MAPE     : {metrics_rf['MAPE']:.2f}%\\n\"\n",
    "        f\"  R2       : {metrics_rf['R2']:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    # ---------- CatBoost ----------\n",
    "    cat_model = build_catboost_model()\n",
    "    cat_feature_indices = [X_train.columns.get_loc(col) for col in CAT_FEATURES]\n",
    "\n",
    "    cat_model.fit(X_train, y_train, cat_features=cat_feature_indices)\n",
    "    y_pred_cat = cat_model.predict(X_valid)\n",
    "    metrics_cat = compute_metrics(y_valid, y_pred_cat)\n",
    "    metrics_all[\"catboost\"] = metrics_cat\n",
    "\n",
    "    print(\"Model: CatBoost\")\n",
    "    print(\n",
    "        f\"  MAE      : {metrics_cat['MAE']:.2f} ({metrics_cat['MAE_pct']:.2f}%)\\n\"\n",
    "        f\"  RMSE     : {metrics_cat['RMSE']:.2f} ({metrics_cat['RMSE_pct']:.2f}%)\\n\"\n",
    "        f\"  MedianAE : {metrics_cat['MedianAE']:.2f} ({metrics_cat['MedianAE_pct']:.2f}%)\\n\"\n",
    "        f\"  MAPE     : {metrics_cat['MAPE']:.2f}%\\n\"\n",
    "        f\"  R2       : {metrics_cat['R2']:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    return metrics_all, cat_model\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 6. Build 2025 feature rows and predict with CatBoost\n",
    "# =========================================================\n",
    "def build_2025_features_from_lagged(df_lagged: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construct feature rows for the year 2025 based on lag information\n",
    "    available up to 2024.\n",
    "\n",
    "    For each (model, region, fuel_type, transmission, color) group:\n",
    "        - sales_last1_2025 = 2024 sales_volume\n",
    "        - sales_last2_2025 = 2024 sales_last1\n",
    "        - sales_avg3_2025  = average of (2024, 2023, 2022) sales_volume\n",
    "        - price_last1, mileage_last1 for 2025 are copied from 2024\n",
    "        - price_trend and mileage_trend are reused from 2024\n",
    "\n",
    "    The target column sales_volume is set to NaN for 2025 rows.\n",
    "    \"\"\"\n",
    "    group_cols = [\"model\", \"region\", \"fuel_type\", \"transmission\", \"color\"]\n",
    "\n",
    "    df_sorted = df_lagged.sort_values(group_cols + [\"year\"])\n",
    "    last_rows = df_sorted.groupby(group_cols, as_index=False).tail(1)\n",
    "\n",
    "    # Keep only combinations with complete lag information\n",
    "    last_rows = last_rows.dropna(\n",
    "        subset=[\"sales_last1\", \"sales_last2\", \"sales_avg3\", \"price_last1\", \"mileage_last1\"]\n",
    "    )\n",
    "\n",
    "    rows_2025 = []\n",
    "\n",
    "    for _, row in last_rows.iterrows():\n",
    "        new_row = row.copy()\n",
    "        new_row[\"year\"] = 2025\n",
    "\n",
    "        sales_last1_2025 = row[\"sales_volume\"]\n",
    "        sales_last2_2025 = row[\"sales_last1\"]\n",
    "        sales_avg3_2025 = (\n",
    "            row[\"sales_volume\"] + row[\"sales_last1\"] + row[\"sales_last2\"]\n",
    "        ) / 3\n",
    "\n",
    "        new_row[\"sales_last1\"] = sales_last1_2025\n",
    "        new_row[\"sales_last2\"] = sales_last2_2025\n",
    "        new_row[\"sales_avg3\"] = sales_avg3_2025\n",
    "\n",
    "        if not pd.isna(sales_last2_2025) and sales_last2_2025 != 0:\n",
    "            new_row[\"sales_growth\"] = (\n",
    "                sales_last1_2025 - sales_last2_2025\n",
    "            ) / sales_last2_2025\n",
    "        else:\n",
    "            new_row[\"sales_growth\"] = 0.0\n",
    "\n",
    "        new_row[\"price_last1\"] = row[\"price_usd\"]\n",
    "        new_row[\"mileage_last1\"] = row[\"mileage_km\"]\n",
    "\n",
    "        # Reuse the existing trend values from the latest year\n",
    "        new_row[\"price_trend\"] = row.get(\"price_trend\", 0.0)\n",
    "        new_row[\"mileage_trend\"] = row.get(\"mileage_trend\", 0.0)\n",
    "\n",
    "        # Actual 2025 sales are unknown\n",
    "        new_row[\"sales_volume\"] = np.nan\n",
    "\n",
    "        rows_2025.append(new_row)\n",
    "\n",
    "    feat_2025 = pd.DataFrame(rows_2025)\n",
    "    # Ensure column ordering: all features first, then sales_volume\n",
    "    feat_2025 = feat_2025[[c for c in feat_2025.columns if c not in [\"sales_volume\"]] + [\"sales_volume\"]]\n",
    "\n",
    "    return feat_2025\n",
    "\n",
    "\n",
    "def retrain_catboost_and_predict_2025(df_lagged: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Retrain CatBoost on all available data from 2020–2024 and\n",
    "    predict 2025 sales using constructed 2025 feature rows.\n",
    "\n",
    "    The function:\n",
    "        - Cleans and uses all rows with non-missing features and target\n",
    "        - Builds 2025 feature rows from lagged data\n",
    "        - Fits a new CatBoost model on 2020–2024\n",
    "        - Predicts row-level 2025 sales\n",
    "        - Aggregates predictions by several dimensions (model, region,\n",
    "          fuel_type, transmission, color)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_lagged : pd.DataFrame\n",
    "        Lag-augmented historical data including sales_volume.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    total_2025 : float\n",
    "        Total predicted sales volume for 2025.\n",
    "    feat_2025_out : pd.DataFrame\n",
    "        Row-level 2025 feature DataFrame with predictions attached.\n",
    "    by_model : pd.DataFrame\n",
    "        Predicted 2025 sales aggregated by model.\n",
    "    by_region : pd.DataFrame\n",
    "        Predicted 2025 sales aggregated by region.\n",
    "    by_fuel : pd.DataFrame\n",
    "        Predicted 2025 sales aggregated by fuel_type.\n",
    "    by_trans : pd.DataFrame\n",
    "        Predicted 2025 sales aggregated by transmission.\n",
    "    by_color : pd.DataFrame\n",
    "        Predicted 2025 sales aggregated by color.\n",
    "    \"\"\"\n",
    "    df_clean = df_lagged.dropna(subset=FEATURE_COLS + [\"sales_volume\"]).copy()\n",
    "\n",
    "    X_full = df_clean[FEATURE_COLS]\n",
    "    y_full = df_clean[\"sales_volume\"].values\n",
    "\n",
    "    feat_2025 = build_2025_features_from_lagged(df_lagged)\n",
    "    X_2025 = feat_2025[FEATURE_COLS]\n",
    "\n",
    "    cat_model = build_catboost_model()\n",
    "    cat_feature_indices = [X_full.columns.get_loc(col) for col in CAT_FEATURES]\n",
    "    cat_model.fit(X_full, y_full, cat_features=cat_feature_indices)\n",
    "\n",
    "    preds_2025 = cat_model.predict(X_2025)\n",
    "    total_2025 = preds_2025.sum()\n",
    "\n",
    "    feat_2025_out = feat_2025.copy()\n",
    "    feat_2025_out[\"pred_sales_volume_2025_catboost\"] = preds_2025\n",
    "\n",
    "    print(f\"\\n=== CatBoost predicted total sales volume in 2025: {total_2025:.2f} ===\\n\")\n",
    "\n",
    "    # Aggregate predictions by different dimensions\n",
    "    col_pred = \"pred_sales_volume_2025_catboost\"\n",
    "\n",
    "    by_model = (\n",
    "        feat_2025_out.groupby(\"model\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "    by_region = (\n",
    "        feat_2025_out.groupby(\"region\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "    by_fuel = (\n",
    "        feat_2025_out.groupby(\"fuel_type\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "    by_trans = (\n",
    "        feat_2025_out.groupby(\"transmission\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "    by_color = (\n",
    "        feat_2025_out.groupby(\"color\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "\n",
    "    return total_2025, feat_2025_out, by_model, by_region, by_fuel, by_trans, by_color\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 7. Metrics comparison table and bar chart\n",
    "# =========================================================\n",
    "def build_metrics_table(metrics_all: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert the metrics dictionary into a DataFrame and\n",
    "    enforce a consistent row ordering for models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metrics_all : dict\n",
    "        Dictionary mapping model names to metric dictionaries.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame indexed by model name with one row per model.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(metrics_all, orient=\"index\")\n",
    "    df.index.name = \"model\"\n",
    "    df = df.loc[[\"xgb\", \"lgbm\", \"rf\", \"catboost\"]]\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_metrics_bar(metrics_df: pd.DataFrame, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Plot a single bar chart comparing four error-related metrics\n",
    "    across multiple models:\n",
    "\n",
    "        - MAE_pct\n",
    "        - RMSE_pct\n",
    "        - MedianAE_pct\n",
    "        - MAPE (already expressed as a percentage)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metrics_df : pd.DataFrame\n",
    "        DataFrame containing metrics for each model (one row per model).\n",
    "    save_path : str, optional\n",
    "        If provided, the bar chart is saved to this path.\n",
    "        Otherwise, the figure is not written to disk.\n",
    "    \"\"\"\n",
    "    models = metrics_df.index.tolist()\n",
    "    x = np.arange(len(models))\n",
    "\n",
    "    metrics_to_plot = [\"MAE_pct\", \"RMSE_pct\", \"MedianAE_pct\", \"MAPE\"]\n",
    "    colors = [\"#1C69D4\", \"#4C8BF5\", \"#82B1FF\", \"#FFB300\"]\n",
    "    width = 0.18\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    for i, (metric, c) in enumerate(zip(metrics_to_plot, colors)):\n",
    "        vals = metrics_df[metric].values\n",
    "        ax.bar(x + i * width - 1.5 * width, vals, width, label=metric, color=c)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=15)\n",
    "    ax.set_ylabel(\"Error / Percentage\")\n",
    "    ax.set_title(\"Model Performance Comparison on 2024 (with lag features)\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 8. Main script entry point\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load and aggregate data\n",
    "    agg_df = load_and_aggregate(FILE_PATH)\n",
    "    print(\"Aggregated shape (before lag):\", agg_df.shape)\n",
    "    print(agg_df.head(), \"\\n\")\n",
    "\n",
    "    # 2. Add lag features\n",
    "    agg_df_lagged = add_lag_features(agg_df)\n",
    "    print(\n",
    "        \"Shape after adding lag features (before dropna):\",\n",
    "        agg_df_lagged.shape,\n",
    "        \"\\n\",\n",
    "    )\n",
    "\n",
    "    # 3. Train and validate models (2020–2023 train, 2024 validate)\n",
    "    metrics_all, cat_model_trained = train_and_validate_models(agg_df_lagged)\n",
    "\n",
    "    # 4. Build metrics comparison table\n",
    "    metrics_df = build_metrics_table(metrics_all)\n",
    "    print(\"\\n=== Model comparison on 2024 validation (with lag, row-level) ===\")\n",
    "    print(metrics_df, \"\\n\")\n",
    "\n",
    "    # 5. Plot bar chart comparing metrics across models\n",
    "    plot_metrics_bar(metrics_df, save_path=\"model_performance_2024_with_lag.png\")\n",
    "    print(\"Saved bar chart to: model_performance_2024_with_lag.png\\n\")\n",
    "\n",
    "    # 6. Use CatBoost to predict 2025 total and segmented sales\n",
    "    (\n",
    "        total_2025_cat,\n",
    "        df_cat_2025,\n",
    "        by_model_2025,\n",
    "        by_region_2025,\n",
    "        by_fuel_2025,\n",
    "        by_trans_2025,\n",
    "        by_color_2025,\n",
    "    ) = retrain_catboost_and_predict_2025(agg_df_lagged)\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by model:\")\n",
    "    print(by_model_2025.head(), \"\\n\")\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by region:\")\n",
    "    print(by_region_2025, \"\\n\")\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by fuel_type:\")\n",
    "    print(by_fuel_2025, \"\\n\")\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by transmission:\")\n",
    "    print(by_trans_2025, \"\\n\")\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by color:\")\n",
    "    print(by_color_2025, \"\\n\")\n",
    "\n",
    "    print(f\"CatBoost (row-level) predicted 2025 total sales: {total_2025_cat:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e71cf",
   "metadata": {},
   "source": [
    "# Comparing to Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06529df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated shape (before lag): (10306, 10)\n",
      "   year     model  region fuel_type transmission   color  engine_size_l  \\\n",
      "0  2020  3 Series  Africa    Diesel    Automatic   Black           2.90   \n",
      "1  2020  3 Series  Africa    Diesel    Automatic    Blue           3.00   \n",
      "2  2020  3 Series  Africa    Diesel    Automatic     Red           3.55   \n",
      "3  2020  3 Series  Africa    Diesel    Automatic  Silver           3.30   \n",
      "4  2020  3 Series  Africa    Diesel       Manual   Black           4.60   \n",
      "\n",
      "   mileage_km  price_usd  sales_volume  \n",
      "0     54293.0   100920.0          8279  \n",
      "1     22846.0    79435.5          6282  \n",
      "2     85078.5   106306.0         14847  \n",
      "3    182077.0    59951.0          2355  \n",
      "4    107799.0    75078.0          3975   \n",
      "\n",
      "=== ARIMA baseline on yearly total sales ===\n",
      "year\n",
      "2020    16310843\n",
      "2021    16884666\n",
      "2022    17920946\n",
      "2023    16268654\n",
      "2024    17527854\n",
      "Name: sales_volume, dtype: int64 \n",
      "\n",
      "ARIMA predicted 2024 total sales: 16227225.32\n",
      "Actual 2024 total sales        : 17527854.00\n",
      "ARIMA metrics (yearly total, 2024 as test):\n",
      "  MAE: 1300628.6829\n",
      "  RMSE: 1300628.6829\n",
      "  MedianAE: 1300628.6829\n",
      "  MAPE: 7.4204\n",
      "  R2: nan\n",
      "  MAE_pct: 7.4204\n",
      "  RMSE_pct: 7.4204\n",
      "  MedianAE_pct: 7.4204\n",
      "\n",
      "=== ARIMA predicted total sales in 2025 (yearly total): 16215877.01 ===\n",
      "\n",
      "Shape after adding lag features (before dropna): (10306, 18) \n",
      "\n",
      "Shape train (with lag): (2343, 17), Shape valid (with lag): (1808, 17)\n",
      "\n",
      "Model: XGBoost\n",
      "  MAE      : 789.90 (9.41%)\n",
      "  RMSE     : 1181.66 (14.08%)\n",
      "  MedianAE : 575.95 (6.86%)\n",
      "  MAPE     : 29.28%\n",
      "  R2       : 0.9559\n",
      "\n",
      "Model: LightGBM\n",
      "  MAE      : 635.31 (7.57%)\n",
      "  RMSE     : 1008.45 (12.01%)\n",
      "  MedianAE : 426.60 (5.08%)\n",
      "  MAPE     : 23.12%\n",
      "  R2       : 0.9679\n",
      "\n",
      "Model: RandomForest\n",
      "  MAE      : 920.21 (10.96%)\n",
      "  RMSE     : 1411.96 (16.82%)\n",
      "  MedianAE : 598.33 (7.13%)\n",
      "  MAPE     : 35.34%\n",
      "  R2       : 0.9370\n",
      "\n",
      "Model: CatBoost\n",
      "  MAE      : 374.77 (4.46%)\n",
      "  RMSE     : 706.72 (8.42%)\n",
      "  MedianAE : 225.13 (2.68%)\n",
      "  MAPE     : 12.76%\n",
      "  R2       : 0.9842\n",
      "\n",
      "\n",
      "=== Model comparison on 2024 validation (with lag, row-level vs yearly) ===\n",
      "                       MAE          RMSE      MedianAE       MAPE        R2  \\\n",
      "model                                                                         \n",
      "arima_yearly  1.300629e+06  1.300629e+06  1.300629e+06   7.420353       NaN   \n",
      "xgb           7.898975e+02  1.181660e+03  5.759468e+02  29.278055  0.955910   \n",
      "lgbm          6.353097e+02  1.008449e+03  4.265955e+02  23.123558  0.967888   \n",
      "rf            9.202118e+02  1.411957e+03  5.983283e+02  35.340780  0.937050   \n",
      "catboost      3.747670e+02  7.067237e+02  2.251266e+02  12.755740  0.984229   \n",
      "\n",
      "                MAE_pct   RMSE_pct  MedianAE_pct  \n",
      "model                                             \n",
      "arima_yearly   7.420353   7.420353      7.420353  \n",
      "xgb            9.409003  14.075552      6.860492  \n",
      "lgbm           7.567604  12.012314      5.081467  \n",
      "rf            10.961265  16.818778      7.127094  \n",
      "catboost       4.464103   8.418264      2.681635   \n",
      "\n",
      "Saved bar chart to: model_performance_2024_with_lag.png\n",
      "\n",
      "\n",
      "=== CatBoost predicted total sales volume in 2025: 19529866.56 ===\n",
      "\n",
      "CatBoost - 2025 predicted sales by model:\n",
      "      model  pred_sales_volume_2025_catboost\n",
      "8        X6                     1.960037e+06\n",
      "2  7 Series                     1.889560e+06\n",
      "5        X1                     1.861147e+06\n",
      "4        M5                     1.829955e+06\n",
      "6        X3                     1.765595e+06 \n",
      "\n",
      "CatBoost - 2025 predicted sales by region:\n",
      "          region  pred_sales_volume_2025_catboost\n",
      "2         Europe                     3.418326e+06\n",
      "3    Middle East                     3.342179e+06\n",
      "1           Asia                     3.246769e+06\n",
      "4  North America                     3.216616e+06\n",
      "0         Africa                     3.172208e+06\n",
      "5  South America                     3.133768e+06 \n",
      "\n",
      "CatBoost - 2025 predicted sales by fuel_type:\n",
      "  fuel_type  pred_sales_volume_2025_catboost\n",
      "2    Hybrid                     5.003313e+06\n",
      "0    Diesel                     4.888898e+06\n",
      "1  Electric                     4.832577e+06\n",
      "3    Petrol                     4.805079e+06 \n",
      "\n",
      "CatBoost - 2025 predicted sales by transmission:\n",
      "  transmission  pred_sales_volume_2025_catboost\n",
      "1       Manual                     9.911152e+06\n",
      "0    Automatic                     9.618715e+06 \n",
      "\n",
      "CatBoost - 2025 predicted sales by color:\n",
      "    color  pred_sales_volume_2025_catboost\n",
      "3     Red                     3.379653e+06\n",
      "0   Black                     3.343638e+06\n",
      "1    Blue                     3.311630e+06\n",
      "5   White                     3.306206e+06\n",
      "4  Silver                     3.204625e+06\n",
      "2    Grey                     2.984115e+06 \n",
      "\n",
      "ARIMA (yearly total) predicted 2025 sales: 16215877.01\n",
      "CatBoost (row-level) predicted 2025 sales: 19529866.56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error,\n",
    "    r2_score,\n",
    "    median_absolute_error,\n",
    ")\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# =========================================================\n",
    "# 0. Global configuration\n",
    "# =========================================================\n",
    "FILE_PATH = \"../data/processed/bmw_sales_2020_2024_clean.csv\"\n",
    "\n",
    "CAT_FEATURES = [\"model\", \"region\", \"fuel_type\", \"transmission\", \"color\"]\n",
    "NUM_FEATURES = [\"year\", \"engine_size_l\", \"mileage_km\", \"price_usd\"]\n",
    "FEATURE_COLS = CAT_FEATURES + NUM_FEATURES\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. Aggregate raw data (by year + category combination)\n",
    "# =========================================================\n",
    "def load_and_aggregate(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load the raw dataset and aggregate it by the combination of:\n",
    "        year + model + region + fuel_type + transmission + color.\n",
    "\n",
    "    Aggregation rules:\n",
    "        - engine_size_l, mileage_km, price_usd: mean value\n",
    "        - sales_volume: sum\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    group_cols = [\"year\", \"model\", \"region\", \"fuel_type\", \"transmission\", \"color\"]\n",
    "\n",
    "    agg_df = (\n",
    "        df.groupby(group_cols, as_index=False)\n",
    "        .agg(\n",
    "            {\n",
    "                \"engine_size_l\": \"mean\",\n",
    "                \"mileage_km\": \"mean\",\n",
    "                \"price_usd\": \"mean\",\n",
    "                \"sales_volume\": \"sum\",\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return agg_df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. ARIMA baseline on yearly total sales\n",
    "# =========================================================\n",
    "def compute_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Compute generic regression metrics, including:\n",
    "        - MAE / RMSE / MedianAE / MAPE / R2\n",
    "    and percentage metrics relative to the mean of y_true:\n",
    "        - MAE_pct / RMSE_pct / MedianAE_pct\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    # rmse = root_mean_squared_error(y_true, y_pred, squared=False)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    med_ae = median_absolute_error(y_true, y_pred)\n",
    "\n",
    "    # Avoid division by zero when computing MAPE\n",
    "    mask = y_true != 0\n",
    "    if mask.sum() > 0:\n",
    "        mape = (np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])).mean() * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "\n",
    "    if len(y_true) > 1:\n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "    else:\n",
    "        # R2 is not meaningful for a single data point\n",
    "        r2 = np.nan\n",
    "\n",
    "    mean_y = y_true.mean()\n",
    "    mae_pct = mae / mean_y * 100 if mean_y != 0 else np.nan\n",
    "    rmse_pct = rmse / mean_y * 100 if mean_y != 0 else np.nan\n",
    "    med_ae_pct = med_ae / mean_y * 100 if mean_y != 0 else np.nan\n",
    "\n",
    "    return {\n",
    "        \"MAE\": mae,\n",
    "        \"RMSE\": rmse,\n",
    "        \"MedianAE\": med_ae,\n",
    "        \"MAPE\": mape,\n",
    "        \"R2\": r2,\n",
    "        \"MAE_pct\": mae_pct,\n",
    "        \"RMSE_pct\": rmse_pct,\n",
    "        \"MedianAE_pct\": med_ae_pct,\n",
    "    }\n",
    "\n",
    "\n",
    "def arima_baseline_yearly(df_agg: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Build an ARIMA baseline model on yearly total sales:\n",
    "\n",
    "    - Training: 2020–2023\n",
    "    - Testing: 2024\n",
    "    - Forecast: 2025 total sales\n",
    "\n",
    "    The model is fitted on annual total sales and used to:\n",
    "        1) Evaluate 2024 as a one-step-ahead forecast\n",
    "        2) Forecast 2025 total sales\n",
    "    \"\"\"\n",
    "    df_yearly = (\n",
    "        df_agg.groupby(\"year\")[\"sales_volume\"].sum().sort_index()\n",
    "    )  # Series: index=year, value=total sales\n",
    "\n",
    "    print(\"=== ARIMA baseline on yearly total sales ===\")\n",
    "    print(df_yearly, \"\\n\")\n",
    "\n",
    "    train_series = df_yearly[df_yearly.index < 2024]\n",
    "    test_value = df_yearly.loc[2024]\n",
    "\n",
    "    # Simple ARIMA(1,1,1) configuration\n",
    "    model = ARIMA(train_series, order=(1, 1, 1))\n",
    "    fitted = model.fit()\n",
    "\n",
    "    # One-step forecast for 2024 (used as the test point)\n",
    "    pred_2024 = float(fitted.forecast(steps=1).iloc[0])\n",
    "    print(f\"ARIMA predicted 2024 total sales: {pred_2024:.2f}\")\n",
    "    print(f\"Actual 2024 total sales        : {float(test_value):.2f}\")\n",
    "\n",
    "    metrics_2024 = compute_metrics(\n",
    "        np.array([test_value], dtype=float), np.array([pred_2024], dtype=float)\n",
    "    )\n",
    "\n",
    "    print(\"ARIMA metrics (yearly total, 2024 as test):\")\n",
    "    for k, v in metrics_2024.items():\n",
    "        print(f\"  {k}: {v:.4f}\")\n",
    "    print()\n",
    "\n",
    "    # Forecast two steps ahead and take the second value as the 2025 forecast\n",
    "    pred_2025 = float(fitted.forecast(steps=2).iloc[-1])\n",
    "    print(f\"=== ARIMA predicted total sales in 2025 (yearly total): {pred_2025:.2f} ===\\n\")\n",
    "\n",
    "    return metrics_2024, pred_2025\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. Lag feature construction (for ML models)\n",
    "# =========================================================\n",
    "def add_lag_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add lag-based features for each combination of:\n",
    "        model + region + fuel_type + transmission + color.\n",
    "\n",
    "    Newly created features:\n",
    "        - sales_last1, sales_last2\n",
    "        - sales_avg3\n",
    "        - sales_growth\n",
    "        - price_last1, price_trend\n",
    "        - mileage_last1, mileage_trend\n",
    "\n",
    "    The global NUM_FEATURES and FEATURE_COLS lists are updated to\n",
    "    include these lag-based numeric features.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(\n",
    "        [\"model\", \"region\", \"fuel_type\", \"transmission\", \"color\", \"year\"]\n",
    "    ).copy()\n",
    "\n",
    "    group_cols = [\"model\", \"region\", \"fuel_type\", \"transmission\", \"color\"]\n",
    "\n",
    "    df[\"sales_last1\"] = df.groupby(group_cols)[\"sales_volume\"].shift(1)\n",
    "    df[\"sales_last2\"] = df.groupby(group_cols)[\"sales_volume\"].shift(2)\n",
    "\n",
    "    df[\"sales_avg3\"] = df.groupby(group_cols)[\"sales_volume\"].transform(\n",
    "        lambda x: x.rolling(3).mean()\n",
    "    )\n",
    "\n",
    "    df[\"sales_growth\"] = (df[\"sales_last1\"] - df[\"sales_last2\"]) / df[\"sales_last2\"]\n",
    "\n",
    "    df[\"price_last1\"] = df.groupby(group_cols)[\"price_usd\"].shift(1)\n",
    "    df[\"price_trend\"] = (df[\"price_usd\"] - df[\"price_last1\"]) / df[\"price_last1\"]\n",
    "\n",
    "    df[\"mileage_last1\"] = df.groupby(group_cols)[\"mileage_km\"].shift(1)\n",
    "    df[\"mileage_trend\"] = (df[\"mileage_km\"] - df[\"mileage_last1\"]) / df[\"mileage_last1\"]\n",
    "\n",
    "    # Update numeric feature list with lag features\n",
    "    lag_num_features = [\n",
    "        \"sales_last1\",\n",
    "        \"sales_last2\",\n",
    "        \"sales_avg3\",\n",
    "        \"sales_growth\",\n",
    "        \"price_last1\",\n",
    "        \"price_trend\",\n",
    "        \"mileage_last1\",\n",
    "        \"mileage_trend\",\n",
    "    ]\n",
    "\n",
    "    global NUM_FEATURES, FEATURE_COLS\n",
    "    NUM_FEATURES = [\"year\", \"engine_size_l\", \"mileage_km\", \"price_usd\"] + lag_num_features\n",
    "    FEATURE_COLS = CAT_FEATURES + NUM_FEATURES\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 4. Build model pipelines\n",
    "# =========================================================\n",
    "def build_xgb_pipeline():\n",
    "    \"\"\"\n",
    "    Build an XGBoost regression pipeline with preprocessing.\n",
    "\n",
    "    The pipeline includes:\n",
    "        - One-hot encoding for categorical features\n",
    "        - Passthrough for numeric features\n",
    "        - XGBRegressor as the final estimator\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_FEATURES),\n",
    "            (\"num\", \"passthrough\", NUM_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    return Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", xgb)])\n",
    "\n",
    "\n",
    "def build_lgbm_pipeline():\n",
    "    \"\"\"\n",
    "    Build a LightGBM regression pipeline with preprocessing.\n",
    "\n",
    "    The pipeline includes:\n",
    "        - One-hot encoding for categorical features\n",
    "        - Passthrough for numeric features\n",
    "        - LGBMRegressor as the final estimator\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_FEATURES),\n",
    "            (\"num\", \"passthrough\", NUM_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    lgbm = LGBMRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=-1,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        objective=\"regression\",\n",
    "        verbose=-1,\n",
    "    )\n",
    "\n",
    "    return Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", lgbm)])\n",
    "\n",
    "\n",
    "def build_rf_pipeline():\n",
    "    \"\"\"\n",
    "    Build a RandomForest regression pipeline with preprocessing.\n",
    "\n",
    "    The pipeline includes:\n",
    "        - One-hot encoding for categorical features\n",
    "        - Passthrough for numeric features\n",
    "        - RandomForestRegressor as the final estimator\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_FEATURES),\n",
    "            (\"num\", \"passthrough\", NUM_FEATURES),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    return Pipeline(steps=[(\"preprocess\", preprocessor), (\"model\", rf)])\n",
    "\n",
    "\n",
    "def build_catboost_model():\n",
    "    \"\"\"\n",
    "    Build a CatBoostRegressor model.\n",
    "\n",
    "    CatBoost directly uses the DataFrame as input and expects\n",
    "    categorical feature indices passed via the cat_features parameter.\n",
    "    \"\"\"\n",
    "    return CatBoostRegressor(\n",
    "        depth=8,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=800,\n",
    "        loss_function=\"RMSE\",\n",
    "        eval_metric=\"RMSE\",\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 5. Training and validation (2020–2023 train, 2024 validate)\n",
    "# =========================================================\n",
    "def train_and_validate_models(df_lagged: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Train XGBoost, LightGBM, RandomForest, and CatBoost on data with lag features,\n",
    "    and evaluate them on the 2024 validation set.\n",
    "\n",
    "    Training/validation split:\n",
    "        - Training: years < 2024\n",
    "        - Validation: year == 2024\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_lagged : pd.DataFrame\n",
    "        Input DataFrame with lag features and sales_volume.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    metrics_all : dict\n",
    "        Dictionary of evaluation metrics for each model on 2024.\n",
    "    cat_model : CatBoostRegressor\n",
    "        Trained CatBoost model (can be reused later).\n",
    "    \"\"\"\n",
    "    # Drop rows with NaN in lag features or target\n",
    "    df_clean = df_lagged.dropna(subset=FEATURE_COLS + [\"sales_volume\"]).copy()\n",
    "\n",
    "    # Split by year\n",
    "    train_df = df_clean[df_clean[\"year\"] < 2024]\n",
    "    valid_df = df_clean[df_clean[\"year\"] == 2024]\n",
    "\n",
    "    X_train = train_df[FEATURE_COLS]\n",
    "    y_train = train_df[\"sales_volume\"].values\n",
    "\n",
    "    X_valid = valid_df[FEATURE_COLS]\n",
    "    y_valid = valid_df[\"sales_volume\"].values\n",
    "\n",
    "    print(\n",
    "        f\"Shape train (with lag): {X_train.shape}, \"\n",
    "        f\"Shape valid (with lag): {X_valid.shape}\\n\"\n",
    "    )\n",
    "\n",
    "    metrics_all = {}\n",
    "\n",
    "    # ---------- XGBoost ----------\n",
    "    xgb_model = build_xgb_pipeline()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred_xgb = xgb_model.predict(X_valid)\n",
    "    metrics_xgb = compute_metrics(y_valid, y_pred_xgb)\n",
    "    metrics_all[\"xgb\"] = metrics_xgb\n",
    "\n",
    "    print(\"Model: XGBoost\")\n",
    "    print(\n",
    "        f\"  MAE      : {metrics_xgb['MAE']:.2f} ({metrics_xgb['MAE_pct']:.2f}%)\\n\"\n",
    "        f\"  RMSE     : {metrics_xgb['RMSE']:.2f} ({metrics_xgb['RMSE_pct']:.2f}%)\\n\"\n",
    "        f\"  MedianAE : {metrics_xgb['MedianAE']:.2f} ({metrics_xgb['MedianAE_pct']:.2f}%)\\n\"\n",
    "        f\"  MAPE     : {metrics_xgb['MAPE']:.2f}%\\n\"\n",
    "        f\"  R2       : {metrics_xgb['R2']:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    # ---------- LightGBM ----------\n",
    "    lgbm_model = build_lgbm_pipeline()\n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "    y_pred_lgbm = lgbm_model.predict(X_valid)\n",
    "    metrics_lgbm = compute_metrics(y_valid, y_pred_lgbm)\n",
    "    metrics_all[\"lgbm\"] = metrics_lgbm\n",
    "\n",
    "    print(\"Model: LightGBM\")\n",
    "    print(\n",
    "        f\"  MAE      : {metrics_lgbm['MAE']:.2f} ({metrics_lgbm['MAE_pct']:.2f}%)\\n\"\n",
    "        f\"  RMSE     : {metrics_lgbm['RMSE']:.2f} ({metrics_lgbm['RMSE_pct']:.2f}%)\\n\"\n",
    "        f\"  MedianAE : {metrics_lgbm['MedianAE']:.2f} ({metrics_lgbm['MedianAE_pct']:.2f}%)\\n\"\n",
    "        f\"  MAPE     : {metrics_lgbm['MAPE']:.2f}%\\n\"\n",
    "        f\"  R2       : {metrics_lgbm['R2']:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    # ---------- RandomForest ----------\n",
    "    rf_model = build_rf_pipeline()\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_rf = rf_model.predict(X_valid)\n",
    "    metrics_rf = compute_metrics(y_valid, y_pred_rf)\n",
    "    metrics_all[\"rf\"] = metrics_rf\n",
    "\n",
    "    print(\"Model: RandomForest\")\n",
    "    print(\n",
    "        f\"  MAE      : {metrics_rf['MAE']:.2f} ({metrics_rf['MAE_pct']:.2f}%)\\n\"\n",
    "        f\"  RMSE     : {metrics_rf['RMSE']:.2f} ({metrics_rf['RMSE_pct']:.2f}%)\\n\"\n",
    "        f\"  MedianAE : {metrics_rf['MedianAE']:.2f} ({metrics_rf['MedianAE_pct']:.2f}%)\\n\"\n",
    "        f\"  MAPE     : {metrics_rf['MAPE']:.2f}%\\n\"\n",
    "        f\"  R2       : {metrics_rf['R2']:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    # ---------- CatBoost ----------\n",
    "    cat_model = build_catboost_model()\n",
    "    cat_feature_indices = [X_train.columns.get_loc(col) for col in CAT_FEATURES]\n",
    "\n",
    "    cat_model.fit(X_train, y_train, cat_features=cat_feature_indices)\n",
    "    y_pred_cat = cat_model.predict(X_valid)\n",
    "    metrics_cat = compute_metrics(y_valid, y_pred_cat)\n",
    "    metrics_all[\"catboost\"] = metrics_cat\n",
    "\n",
    "    print(\"Model: CatBoost\")\n",
    "    print(\n",
    "        f\"  MAE      : {metrics_cat['MAE']:.2f} ({metrics_cat['MAE_pct']:.2f}%)\\n\"\n",
    "        f\"  RMSE     : {metrics_cat['RMSE']:.2f} ({metrics_cat['RMSE_pct']:.2f}%)\\n\"\n",
    "        f\"  MedianAE : {metrics_cat['MedianAE']:.2f} ({metrics_cat['MedianAE_pct']:.2f}%)\\n\"\n",
    "        f\"  MAPE     : {metrics_cat['MAPE']:.2f}%\\n\"\n",
    "        f\"  R2       : {metrics_cat['R2']:.4f}\\n\"\n",
    "    )\n",
    "\n",
    "    return metrics_all, cat_model\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 6. Construct 2025 features and predict with CatBoost\n",
    "# =========================================================\n",
    "def build_2025_features_from_lagged(df_lagged: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construct feature rows for the year 2025 using lag information\n",
    "    available up to 2024.\n",
    "\n",
    "    For each (model, region, fuel_type, transmission, color) group:\n",
    "        - sales_last1_2025 = 2024 sales_volume\n",
    "        - sales_last2_2025 = 2024 sales_last1\n",
    "        - sales_avg3_2025  = average of (2024, 2023, 2022)\n",
    "        - price_last1_2025, mileage_last1_2025 are copied from 2024\n",
    "        - price_trend and mileage_trend are reused from the latest year\n",
    "\n",
    "    The 2025 sales_volume is set to NaN (unknown target).\n",
    "    \"\"\"\n",
    "    group_cols = [\"model\", \"region\", \"fuel_type\", \"transmission\", \"color\"]\n",
    "\n",
    "    df_sorted = df_lagged.sort_values(group_cols + [\"year\"])\n",
    "    last_rows = df_sorted.groupby(group_cols, as_index=False).tail(1)\n",
    "\n",
    "    # Filter combinations that must have complete lag information\n",
    "    last_rows = last_rows.dropna(\n",
    "        subset=[\"sales_last1\", \"sales_last2\", \"sales_avg3\", \"price_last1\", \"mileage_last1\"]\n",
    "    )\n",
    "\n",
    "    rows_2025 = []\n",
    "\n",
    "    for _, row in last_rows.iterrows():\n",
    "        new_row = row.copy()\n",
    "        new_row[\"year\"] = 2025\n",
    "\n",
    "        sales_last1_2025 = row[\"sales_volume\"]\n",
    "        sales_last2_2025 = row[\"sales_last1\"]\n",
    "        sales_avg3_2025 = (\n",
    "            row[\"sales_volume\"] + row[\"sales_last1\"] + row[\"sales_last2\"]\n",
    "        ) / 3\n",
    "\n",
    "        new_row[\"sales_last1\"] = sales_last1_2025\n",
    "        new_row[\"sales_last2\"] = sales_last2_2025\n",
    "        new_row[\"sales_avg3\"] = sales_avg3_2025\n",
    "\n",
    "        if not pd.isna(sales_last2_2025) and sales_last2_2025 != 0:\n",
    "            new_row[\"sales_growth\"] = (\n",
    "                sales_last1_2025 - sales_last2_2025\n",
    "            ) / sales_last2_2025\n",
    "        else:\n",
    "            new_row[\"sales_growth\"] = 0.0\n",
    "\n",
    "        new_row[\"price_last1\"] = row[\"price_usd\"]\n",
    "        new_row[\"mileage_last1\"] = row[\"mileage_km\"]\n",
    "\n",
    "        # Reuse the original trend values (can also be recomputed if needed)\n",
    "        new_row[\"price_trend\"] = row.get(\"price_trend\", 0.0)\n",
    "        new_row[\"mileage_trend\"] = row.get(\"mileage_trend\", 0.0)\n",
    "\n",
    "        # Actual 2025 sales are unknown\n",
    "        new_row[\"sales_volume\"] = np.nan\n",
    "\n",
    "        rows_2025.append(new_row)\n",
    "\n",
    "    feat_2025 = pd.DataFrame(rows_2025)\n",
    "    # Ensure column ordering is consistent with FEATURE_COLS, with sales_volume at the end\n",
    "    feat_2025 = feat_2025[[c for c in feat_2025.columns if c not in [\"sales_volume\"]] + [\"sales_volume\"]]\n",
    "\n",
    "    return feat_2025\n",
    "\n",
    "\n",
    "def retrain_catboost_and_predict_2025(df_lagged: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Retrain CatBoost using all data from 2020–2024 and\n",
    "    predict 2025 row-level sales using constructed 2025 feature rows.\n",
    "\n",
    "    Steps:\n",
    "        - Clean and use all rows with valid features and target.\n",
    "        - Build 2025 feature rows from lagged data.\n",
    "        - Fit a new CatBoost model on full 2020–2024 data.\n",
    "        - Predict 2025 sales at row level.\n",
    "        - Aggregate predictions by model, region, fuel_type,\n",
    "          transmission, and color.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_lagged : pd.DataFrame\n",
    "        Historical data with lag-based features and sales_volume.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    total_2025 : float\n",
    "        Total predicted 2025 sales volume.\n",
    "    feat_2025_out : pd.DataFrame\n",
    "        Row-level 2025 feature DataFrame with predictions appended.\n",
    "    by_model : pd.DataFrame\n",
    "        Predicted sales aggregated by model.\n",
    "    by_region : pd.DataFrame\n",
    "        Predicted sales aggregated by region.\n",
    "    by_fuel : pd.DataFrame\n",
    "        Predicted sales aggregated by fuel_type.\n",
    "    by_trans : pd.DataFrame\n",
    "        Predicted sales aggregated by transmission.\n",
    "    by_color : pd.DataFrame\n",
    "        Predicted sales aggregated by color.\n",
    "    \"\"\"\n",
    "    df_clean = df_lagged.dropna(subset=FEATURE_COLS + [\"sales_volume\"]).copy()\n",
    "\n",
    "    X_full = df_clean[FEATURE_COLS]\n",
    "    y_full = df_clean[\"sales_volume\"].values\n",
    "\n",
    "    feat_2025 = build_2025_features_from_lagged(df_lagged)\n",
    "    X_2025 = feat_2025[FEATURE_COLS]\n",
    "\n",
    "    cat_model = build_catboost_model()\n",
    "    cat_feature_indices = [X_full.columns.get_loc(col) for col in CAT_FEATURES]\n",
    "    cat_model.fit(X_full, y_full, cat_features=cat_feature_indices)\n",
    "\n",
    "    preds_2025 = cat_model.predict(X_2025)\n",
    "    total_2025 = preds_2025.sum()\n",
    "\n",
    "    feat_2025_out = feat_2025.copy()\n",
    "    feat_2025_out[\"pred_sales_volume_2025_catboost\"] = preds_2025\n",
    "\n",
    "    print(f\"\\n=== CatBoost predicted total sales volume in 2025: {total_2025:.2f} ===\\n\")\n",
    "\n",
    "    # Aggregate predictions by different dimensions\n",
    "    col_pred = \"pred_sales_volume_2025_catboost\"\n",
    "\n",
    "    by_model = (\n",
    "        feat_2025_out.groupby(\"model\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "    by_region = (\n",
    "        feat_2025_out.groupby(\"region\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "    by_fuel = (\n",
    "        feat_2025_out.groupby(\"fuel_type\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "    by_trans = (\n",
    "        feat_2025_out.groupby(\"transmission\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "    by_color = (\n",
    "        feat_2025_out.groupby(\"color\")[col_pred]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "        .sort_values(col_pred, ascending=False)\n",
    "    )\n",
    "\n",
    "    return total_2025, feat_2025_out, by_model, by_region, by_fuel, by_trans, by_color\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 7. Metrics comparison table and single bar chart\n",
    "# =========================================================\n",
    "def build_metrics_table(metrics_all: dict, arima_metrics: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a DataFrame to compare performance metrics across\n",
    "    ARIMA (yearly baseline) and all ML models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metrics_all : dict\n",
    "        Dictionary of metrics for ML models (XGB, LGBM, RF, CatBoost).\n",
    "    arima_metrics : dict\n",
    "        Metrics dictionary for the yearly ARIMA baseline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with one row per model (including ARIMA) and\n",
    "        metric names as columns.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame.from_dict(metrics_all, orient=\"index\")\n",
    "    df.index.name = \"model\"\n",
    "\n",
    "    # Add ARIMA baseline (yearly total)\n",
    "    df.loc[\"arima_yearly\"] = arima_metrics\n",
    "\n",
    "    # Reorder rows for clearer comparison\n",
    "    df = df.loc[[\"arima_yearly\", \"xgb\", \"lgbm\", \"rf\", \"catboost\"]]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_metrics_bar(metrics_df: pd.DataFrame, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Plot a single bar chart comparing four error-related metrics\n",
    "    for all models:\n",
    "\n",
    "        - MAE_pct\n",
    "        - RMSE_pct\n",
    "        - MedianAE_pct\n",
    "        - MAPE (already in percentage)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metrics_df : pd.DataFrame\n",
    "        DataFrame containing metrics for each model (one row per model).\n",
    "    save_path : str, optional\n",
    "        If provided, save the figure to the given path.\n",
    "    \"\"\"\n",
    "    models = metrics_df.index.tolist()\n",
    "    x = np.arange(len(models))\n",
    "\n",
    "    metrics_to_plot = [\"MAE_pct\", \"RMSE_pct\", \"MedianAE_pct\", \"MAPE\"]\n",
    "    colors = [\"#1C69D4\", \"#4C8BF5\", \"#82B1FF\", \"#FFB300\"]\n",
    "    width = 0.18\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    for i, (metric, c) in enumerate(zip(metrics_to_plot, colors)):\n",
    "        vals = metrics_df[metric].values\n",
    "        ax.bar(x + i * width - 1.5 * width, vals, width, label=metric, color=c)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(models, rotation=15)\n",
    "    ax.set_ylabel(\"Error / Percentage\")\n",
    "    ax.set_title(\"Model Performance Comparison on 2024 (with lag features)\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 8. Main workflow\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load and aggregate raw data\n",
    "    agg_df = load_and_aggregate(FILE_PATH)\n",
    "    print(\"Aggregated shape (before lag):\", agg_df.shape)\n",
    "    print(agg_df.head(), \"\\n\")\n",
    "\n",
    "    # 2. ARIMA yearly baseline (total sales)\n",
    "    arima_metrics_2024, arima_2025_pred = arima_baseline_yearly(agg_df)\n",
    "\n",
    "    # 3. Add lag features\n",
    "    agg_df_lagged = add_lag_features(agg_df)\n",
    "    print(\n",
    "        \"Shape after adding lag features (before dropna):\",\n",
    "        agg_df_lagged.shape,\n",
    "        \"\\n\",\n",
    "    )\n",
    "\n",
    "    # 4. Train and validate models (2020–2023 train, 2024 validate)\n",
    "    metrics_all, cat_model_trained = train_and_validate_models(agg_df_lagged)\n",
    "\n",
    "    # 5. Build metrics comparison table (including percentages)\n",
    "    metrics_df = build_metrics_table(metrics_all, arima_metrics_2024)\n",
    "    print(\"\\n=== Model comparison on 2024 validation (with lag, row-level vs yearly) ===\")\n",
    "    print(metrics_df, \"\\n\")\n",
    "\n",
    "    # 6. Plot a single bar chart comparing metrics across models\n",
    "    plot_metrics_bar(metrics_df, save_path=\"model_performance_2024_with_lag.png\")\n",
    "    print(\"Saved bar chart to: model_performance_2024_with_lag.png\\n\")\n",
    "\n",
    "    # 7. Use CatBoost to forecast 2025 total and segmented sales\n",
    "    (\n",
    "        total_2025_cat,\n",
    "        df_cat_2025,\n",
    "        by_model_2025,\n",
    "        by_region_2025,\n",
    "        by_fuel_2025,\n",
    "        by_trans_2025,\n",
    "        by_color_2025,\n",
    "    ) = retrain_catboost_and_predict_2025(agg_df_lagged)\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by model:\")\n",
    "    print(by_model_2025.head(), \"\\n\")\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by region:\")\n",
    "    print(by_region_2025, \"\\n\")\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by fuel_type:\")\n",
    "    print(by_fuel_2025, \"\\n\")\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by transmission:\")\n",
    "    print(by_trans_2025, \"\\n\")\n",
    "\n",
    "    print(\"CatBoost - 2025 predicted sales by color:\")\n",
    "    print(by_color_2025, \"\\n\")\n",
    "\n",
    "    print(f\"ARIMA (yearly total) predicted 2025 sales: {arima_2025_pred:.2f}\")\n",
    "    print(f\"CatBoost (row-level) predicted 2025 sales: {total_2025_cat:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d08f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
